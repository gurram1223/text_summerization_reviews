{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of textSummerization.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1AZ9GGmzT7tGUFbP0DBxqKVinBZ5nVkXs","authorship_tag":"ABX9TyNiCRui4RmXW3SfNB8LpE4U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"NFh_IjTEOmDs","colab_type":"code","outputId":"7ca8aedb-73f6-436d-85f2-79b0ffc8775a","executionInfo":{"status":"ok","timestamp":1586824142502,"user_tz":-330,"elapsed":1565,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%matplotlib inline\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import csv\n","import random\n","import re\n","import os\n","import codecs\n","from io import open\n","import itertools\n","import math\n","\n","import numpy as np  \n","import pandas as pd \n","import nltk\n","# nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from bs4 import BeautifulSoup\n","\n","import warnings\n","pd.set_option(\"display.max_colwidth\", 5000)\n","warnings.filterwarnings(\"ignore\")\n","\n","USE_CUDA = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","device"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"GiV-fGd8QO3W","colab_type":"code","outputId":"dfd97618-ee2c-4069-c842-c9d529b880d9","executionInfo":{"status":"ok","timestamp":1584211988748,"user_tz":-330,"elapsed":8039,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Text_Summerization/Reviews.csv\")\n","data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(568454, 10)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"3a9LBqkuohgR","colab_type":"code","colab":{}},"source":["data.sort_values(['Time'], ascending=True,inplace=True) # sorting by time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TO5Lkoh1QO8G","colab_type":"code","outputId":"cff5bbf2-d044-4768-f74a-1dd4090275ae","executionInfo":{"status":"ok","timestamp":1584211996096,"user_tz":-330,"elapsed":995,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":414}},"source":["data[['Text','Summary']].tail()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>477559</th>\n","      <td>The only reason I am giving it 4 stars instead of 5 stars is for the strange can design -- a substantial amount of food sticks to the inside of the can and in the crevice under the top lip, long before the can is empty, and I have to use a baby food spatula to scrape this off.&lt;br /&gt;&lt;br /&gt;That being said, Cee Cee kitty devours this. It is not grain free -- as it does have Brown Rice in it (listed as the 8th ingredient, so it DOES have plenty of meat and fish protein), but the meat as well as the other ingredients more than make up for this. Felidae Canned Cat Food for Adult Cats and Kittens, Formula with Chicken, Turkey, Lamb and Ocean Fish  also smells very fresh and not garbagey like some of the supermarket cat foods. And since Cee Cee is battling hyperthryoidism as well as a heart murmur, I want to buy her the best food I can afford. This may be a bit pricey but it is VERY dense, so it goes a long way.</td>\n","      <td>Cee Cee LOOOVES it, This I Know</td>\n","    </tr>\n","    <tr>\n","      <th>143110</th>\n","      <td>Very pleased with the quality of the espresso.  The pods are sturdy enough to withstand the pressure of the water in brewing - no messy grounds from broken pods to threaten the functioning of the machine.  The crema is awesome, taste is smooth.</td>\n","      <td>Wonderful taste!</td>\n","    </tr>\n","    <tr>\n","      <th>110116</th>\n","      <td>I just love it, and I am Not a major Indian cooking fan--just enough. Really, it mixes with anything you are doing like &lt;a href=\"http://www.amazon.com/gp/product/B000FIXT2I\"&gt;Steamed Brown Rice Bowl, Organic, Microwaveable, 7.4-Ounce Bowls (Pack of 12)&lt;/a&gt; (I use these for convenience, and then I don't eat the whole pot of rice). In many kinds of soups, etc. Beef it up with some &lt;a href=\"http://www.amazon.com/gp/product/B001FA1KLW\"&gt;Amore Tomato Paste, 4.5-Ounce Tubes (Pack of 12)&lt;/a&gt;, which is so, so convenient. Sweeten to taste if you prefer. Here's the best artificial sweetener on Amazon &lt;a href=\"http://www.amazon.com/gp/product/B0019LTH3U\"&gt;NuNaturals Nustevia Alcohol Free Stevia Glass Bottle Liquid, 2-Ounce&lt;/a&gt;. (Stop using Splenda which contains three Chlorine moities. It's essentially bleach, folks.) Enjoy, lentils are so healthy, and this way they really have flavor!&lt;br /&gt;FYI: This costs $3-5/PER PACK at our local stores when you can find it. It is Not overpriced, as someone here said.</td>\n","      <td>It's FANTASTIC! Mixes with Many kinds of Soups, etc. Yes.</td>\n","    </tr>\n","    <tr>\n","      <th>468445</th>\n","      <td>I enjoy drinking this in a greek yogurt smoothie in the morning.  I use greek yogurt, pineapple, banana, and green superfood chocolate powder!  Delicious!</td>\n","      <td>Great Product</td>\n","    </tr>\n","    <tr>\n","      <th>440835</th>\n","      <td>Aside from a non-flashy name, this is a great coffee.  Very smooth, perfect!  If is my favorite at this point, even over other flavored coffee.</td>\n","      <td>Boring name but great coffee</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Text                                                    Summary\n","477559                                                                                          The only reason I am giving it 4 stars instead of 5 stars is for the strange can design -- a substantial amount of food sticks to the inside of the can and in the crevice under the top lip, long before the can is empty, and I have to use a baby food spatula to scrape this off.<br /><br />That being said, Cee Cee kitty devours this. It is not grain free -- as it does have Brown Rice in it (listed as the 8th ingredient, so it DOES have plenty of meat and fish protein), but the meat as well as the other ingredients more than make up for this. Felidae Canned Cat Food for Adult Cats and Kittens, Formula with Chicken, Turkey, Lamb and Ocean Fish  also smells very fresh and not garbagey like some of the supermarket cat foods. And since Cee Cee is battling hyperthryoidism as well as a heart murmur, I want to buy her the best food I can afford. This may be a bit pricey but it is VERY dense, so it goes a long way.                            Cee Cee LOOOVES it, This I Know\n","143110                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Very pleased with the quality of the espresso.  The pods are sturdy enough to withstand the pressure of the water in brewing - no messy grounds from broken pods to threaten the functioning of the machine.  The crema is awesome, taste is smooth.                                           Wonderful taste!\n","110116  I just love it, and I am Not a major Indian cooking fan--just enough. Really, it mixes with anything you are doing like <a href=\"http://www.amazon.com/gp/product/B000FIXT2I\">Steamed Brown Rice Bowl, Organic, Microwaveable, 7.4-Ounce Bowls (Pack of 12)</a> (I use these for convenience, and then I don't eat the whole pot of rice). In many kinds of soups, etc. Beef it up with some <a href=\"http://www.amazon.com/gp/product/B001FA1KLW\">Amore Tomato Paste, 4.5-Ounce Tubes (Pack of 12)</a>, which is so, so convenient. Sweeten to taste if you prefer. Here's the best artificial sweetener on Amazon <a href=\"http://www.amazon.com/gp/product/B0019LTH3U\">NuNaturals Nustevia Alcohol Free Stevia Glass Bottle Liquid, 2-Ounce</a>. (Stop using Splenda which contains three Chlorine moities. It's essentially bleach, folks.) Enjoy, lentils are so healthy, and this way they really have flavor!<br />FYI: This costs $3-5/PER PACK at our local stores when you can find it. It is Not overpriced, as someone here said.  It's FANTASTIC! Mixes with Many kinds of Soups, etc. Yes.\n","468445                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     I enjoy drinking this in a greek yogurt smoothie in the morning.  I use greek yogurt, pineapple, banana, and green superfood chocolate powder!  Delicious!                                              Great Product\n","440835                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Aside from a non-flashy name, this is a great coffee.  Very smooth, perfect!  If is my favorite at this point, even over other flavored coffee.                               Boring name but great coffee"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"LDFHf0u9QO--","colab_type":"code","outputId":"38dd5b8f-8b50-4b13-f90b-25a954032834","executionInfo":{"status":"ok","timestamp":1584212003906,"user_tz":-330,"elapsed":2390,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data.drop_duplicates(subset=['Text'],inplace=True)  #dropping duplicates\n","data.dropna(axis=0,inplace=True)   #dropping na\n","data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(393565, 10)"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"CYmEO-TJOwcm","colab_type":"text"},"source":["# Preprocessing \n","\n","1. Convert everything to lowercase\n","2. Remove HTML tags\n","3. Contraction mapping\n","4. Remove (‘s)\n","5. Remove any text inside the parenthesis ( )\n","6. Eliminate punctuations and special characters\n","7. Remove stopwords\n","8. Remove short words"]},{"cell_type":"code","metadata":{"id":"AZOGAj0cQPFs","colab_type":"code","colab":{}},"source":["contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n","\n","                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n","\n","                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n","\n","                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n","\n","                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n","\n","                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n","\n","                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n","\n","                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n","\n","                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n","\n","                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n","\n","                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n","\n","                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n","\n","                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n","\n","                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n","\n","                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n","\n","                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n","\n","                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n","\n","                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n","\n","                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n","\n","                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n","\n","                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n","\n","                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n","\n","                           \"you're\": \"you are\", \"you've\": \"you have\"}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"poFCk112LgG-","colab_type":"code","outputId":"fddd665f-1af9-4a9a-e644-bfd5d2b408da","executionInfo":{"status":"ok","timestamp":1586824148740,"user_tz":-330,"elapsed":678,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["'''import nltk\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('english')) - set(['not'])\n","stop_words\n","stop_words = set(stopwords.words('english')) - set(['not','no'])'''\n","def clean(text, summary = True):\n","    newString = text.lower()\n","    newString = BeautifulSoup(newString, \"lxml\").text\n","    newString = re.sub(r'\\([^)]*\\)', '', newString)\n","    newString = re.sub('\"','', newString)\n","    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n","    newString = re.sub(r\"'s\\b\",\"\",newString)\n","    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n","    if summary:\n","      tokens = [w for w in newString.split()]\n","      long_words=[]\n","      for i in tokens:\n","          if len(i)>1:                  #removing short word < 2\n","              long_words.append(i)  \n","      print(len(long_words))\n","      if len(long_words)==0:\n","          return \"empty_summary_field\"\n","      else:\n","          return (\" \".join(long_words)).strip()\n","    else:\n","      tokens = [w for w in newString.split() if not w in stop_words]\n","      long_words=[]\n","      for i in tokens:\n","          #print(len(i))\n","          if len(i)>=3:                  #removing short word length < 3 \n","              long_words.append(i)  \n","      return (\" \".join(long_words)).strip()\n","\n","text = \"It is not that great product to have as me\"\n","#text = \"I L Y\"\n","print((clean(text,summary=True)))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["10\n","it is not that great product to have as me\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7eODJ8haQPK_","colab_type":"code","outputId":"fca5bf7f-84a8-4c93-f306-dd6cb82ee35f","executionInfo":{"status":"ok","timestamp":1584213938429,"user_tz":-330,"elapsed":230688,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["%%time\n","\n","# There are few sentences with summary as \"no\"\n","\n","# If you working with LSTM’s or other models which capture the semantic meaning and the\n","# meaning of a word depends on the context of the previous text, then it becomes important not to remove stopwords.\n","\n","stop_words = set(stopwords.words('english')) - set(['not'])\n","def clean(text, summary = True):\n","    newString = text.lower()\n","    newString = BeautifulSoup(newString, \"lxml\").text\n","    newString = re.sub(r'\\([^)]*\\)', '', newString)\n","    newString = re.sub('\"','', newString)\n","    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n","    newString = re.sub(r\"'s\\b\",\"\",newString)\n","    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n","    if summary:\n","      tokens = [w for w in newString.split()]\n","      long_words=[]\n","      for i in tokens:\n","          if len(i)>1:                  #removing short word < 2\n","              long_words.append(i)  \n","      #print(len(long_words))\n","      if len(long_words)==0:\n","          return \"empty_summary_field\"\n","      else:\n","          return (\" \".join(long_words)).strip()\n","    else:\n","      tokens = [w for w in newString.split() if not w in stop_words]\n","      long_words=[]\n","      for i in tokens:\n","          #print(len(i))\n","          if len(i)>=3:                  #removing short word length < 3 \n","              long_words.append(i)  \n","      return (\" \".join(long_words)).strip()\n","\n","\n","cleaned_text = []\n","cleaned_summ = []\n","cleaned_text.append([clean(t,summary=False) for t in data['Text']])\n","cleaned_summ.append([clean(t,summary=True) for t in data['Summary']])\n","\n","data['cleaned_text']=cleaned_text[0]\n","data['cleaned_summary']=cleaned_summ[0]\n","\n","#Ex: There are few sentences with summary as \"no\". After clean() this would be an empty string in cleaned_summary. so deleting the entire row.\n","\n","data['cleaned_summary'].replace(\"empty_summary_field\", np.nan, inplace=True)\n","data.dropna(axis=0,inplace=True)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 3min 46s, sys: 2.12 s, total: 3min 48s\n","Wall time: 3min 48s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vKyxcdHRcd7I","colab_type":"code","outputId":"5d7f3110-38dd-4fef-85bf-80fd6b3bbc6f","executionInfo":{"status":"ok","timestamp":1584213944812,"user_tz":-330,"elapsed":2250,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(393215, 12)"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"3JZ2587ZQPCB","colab_type":"code","outputId":"48bb84e3-1b20-471c-ab64-1c5ee8e61247","executionInfo":{"status":"ok","timestamp":1584214375225,"user_tz":-330,"elapsed":3583,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":267}},"source":["import matplotlib.pyplot as plt\n","\n","text_word_count = []\n","summary_word_count = []\n","\n","# populate the lists with sentence lengths\n","for i in data['cleaned_text']:\n","      text_word_count.append(len(str(i).split()))\n","\n","for i in data['cleaned_summary']:\n","      summary_word_count.append(len(str(i).split()))\n","\n","length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n","#length_df.hist(bins = 30)\n","length_df.boxplot()\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6JuZJcShb2aWkP8PoIqNNJaDI+AAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"1e5ktIQ6dwZy","colab_type":"text"},"source":["1. maximum length of a sentence is 1892"]},{"cell_type":"code","metadata":{"id":"l3-Zd-AKrLj7","colab_type":"code","outputId":"fb8d9e68-880a-4bce-9b04-0e42697b17b7","executionInfo":{"status":"ok","timestamp":1584214411167,"user_tz":-330,"elapsed":1674,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(data)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["393215"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"JI7UpNjMr9jf","colab_type":"code","outputId":"472a350b-0c2a-4df5-e59f-35501895070c","executionInfo":{"status":"ok","timestamp":1584214453225,"user_tz":-330,"elapsed":5540,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Here we are only taking data with text length <= 100 and summary length <= 10\n","data = data[[len(str(txt).split(\" \")) <= 100 and len(str(summ).split(\" \")) <= 10 for txt,summ in zip(data['cleaned_text'],data['cleaned_summary'])]]\n","print(len(data))\n","\n","# saving cleaned_text, cleaned_summary to csv\n","data[['cleaned_text','cleaned_summary']].to_csv(\"/content/drive/My Drive/Colab Notebooks/Text_Summerization/Reviews_cleaned.csv\",index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["365941\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fUEQBqrYqmKN","colab_type":"text"},"source":["# Loading Cleaned Data"]},{"cell_type":"code","metadata":{"id":"qDD7NrjbQPO8","colab_type":"code","outputId":"181cd267-fc19-4a4a-bfde-14a96f9fc9f0","executionInfo":{"status":"ok","timestamp":1586824165652,"user_tz":-330,"elapsed":7111,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data_cleaned = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Text_Summerization/Reviews_cleaned.csv\")\n","data_cleaned.shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(365941, 2)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"gXxk3N7etSMV","colab_type":"code","outputId":"0e7d7f6f-955c-4bbd-ee27-7efbc3bfb91a","executionInfo":{"status":"ok","timestamp":1586824165653,"user_tz":-330,"elapsed":7076,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["data_cleaned.tail(2)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cleaned_text</th>\n","      <th>cleaned_summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>365939</th>\n","      <td>enjoy drinking greek yogurt smoothie morning use greek yogurt pineapple banana green superfood chocolate powder delicious</td>\n","      <td>great product</td>\n","    </tr>\n","    <tr>\n","      <th>365940</th>\n","      <td>aside non flashy name great coffee smooth perfect favorite point even flavored coffee</td>\n","      <td>boring name but great coffee</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                     cleaned_text               cleaned_summary\n","365939  enjoy drinking greek yogurt smoothie morning use greek yogurt pineapple banana green superfood chocolate powder delicious                 great product\n","365940                                      aside non flashy name great coffee smooth perfect favorite point even flavored coffee  boring name but great coffee"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"uK4eEw2GQO6X","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","x_train,x_val,y_train,y_val=train_test_split(data_cleaned['cleaned_text'],data_cleaned['cleaned_summary'],test_size=0.05,random_state=0) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JpIxUjY8kI_X","colab_type":"code","outputId":"d2ce4cf9-47ed-4d4e-cf5b-96bb27d953dc","executionInfo":{"status":"ok","timestamp":1586824165654,"user_tz":-330,"elapsed":6992,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print(len(x_train))\n","print(len(x_val))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["347643\n","18298\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qZ5FgF5OQO1y","colab_type":"code","colab":{}},"source":["# Default word tokens\n","PAD_token = 0  # Used for padding short sentences\n","SOS_token = 1  # Start-of-sentence token\n","EOS_token = 2  # End-of-sentence token\n","RARE_WORD = 3  # word not present in train data replace with this word\n","\n","class Voc:\n","    def __init__(self):\n","        self.trimmed = False\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\", RARE_WORD:\"UNKNOWN\"}\n","        self.num_words = 4  # Count SOS, EOS, PAD\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.num_words\n","            self.word2count[word] = 1\n","            self.index2word[self.num_words] = word\n","            self.num_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","    # Remove words below a certain count threshold\n","    def trim(self, min_count):\n","        if self.trimmed:\n","            return\n","        self.trimmed = True\n","\n","        keep_words = []\n","\n","        for k, v in self.word2count.items():\n","            if v >= min_count:\n","                keep_words.append(k)\n","\n","        print('keep_words {} / {} = {:.4f}'.format(\n","            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n","        ))\n","\n","        # Reinitialize dictionaries\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.num_words = 3 # Count default tokens\n","\n","        for word in keep_words:\n","            self.addWord(word)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KY3e5qDFQOo9","colab_type":"code","outputId":"338c1165-de59-4ed0-9e51-c5dd119ee93c","executionInfo":{"status":"ok","timestamp":1586824171780,"user_tz":-330,"elapsed":13087,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["def toPairs(x_train,y_train,x_val,y_val):\n","  pairs_train = []\n","  pairs_val = []\n","  for x,y in zip(x_train,y_train):\n","    pairs_train.append([str(x), str(y)])\n","\n","  for x,y in zip(x_val,y_val):\n","    pairs_val.append([str(x), str(y)])\n","\n","  return pairs_train,pairs_val\n","\n","# Using the functions defined above, return a populated voc object and pairs list\n","def loadPrepareData(pairs_train,voc):\n","    print(\"Counting words...\")\n","    for pair in pairs_train:\n","        voc.addSentence(pair[0])\n","        voc.addSentence(pair[1])\n","    print(\"Counted words:\", voc.num_words)\n","    return voc\n","\n","# Load/Assemble voc and pairs\n","voc = Voc()\n","save_dir = os.path.join(\"/content/drive/My Drive/Colab Notebooks/Text_Summerization/\", \"save\")\n","pairs_train,pairs_val = toPairs(x_train,y_train,x_val,y_val)\n","voc = loadPrepareData(pairs_train,voc)\n","# Print some pairs to validate\n","print(\"\\npairs:\")\n","for pair in pairs_train[:5]:\n","    print(pair)\n","print(len(pairs_train))\n","print(len(pairs_val))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Counting words...\n","Counted words: 105623\n","\n","pairs:\n","['gluten free years first cookies tasted actually taste like cookie cardboard taste mentioned hard crunchy cookie especially love using similar biscotti dunking coffee', 'yum']\n","['used product years put handful dried apples bottom bowl put oatmealon top zap add walnuts dried cranberries yummy', 'great product']\n","['received satsuki azalea gift person gave excited box opened wat found box small bush not cut not trained nothing even close picture not mean flowers well thought job train means however intent gift giver', 'just small bush']\n","['love small bags perfect take lunch adds nice crunch sandwich bold flavor little bit spicier original', 'delicious and crunchy']\n","['tried different sugar substitutes one terrible anyone given clue bad would not purchased use xylitol stevia sweetner tried say not buy product want sweeten anything not work cannot give away one wants sorry review honest', 'not worth it']\n","347643\n","18298\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pE56enG2jMZz","colab_type":"code","outputId":"720da497-6c67-4726-c8dc-ca29d42d337a","executionInfo":{"status":"ok","timestamp":1586824174290,"user_tz":-330,"elapsed":15580,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["MIN_COUNT = 3    # Minimum word count threshold for trimming\n","\n","def trimRareWords(voc, pairs, MIN_COUNT):\n","    # Trim words used under the MIN_COUNT from the voc\n","    voc.trim(MIN_COUNT)\n","    # Filter out pairs with trimmed words\n","    keep_pairs = []\n","    for pair in pairs:\n","        input_sentence = pair[0]\n","        output_sentence = pair[1]\n","        keep_input = True\n","        keep_output = True\n","        # Check input sentence\n","        for word in input_sentence.split(' '):\n","            if word not in voc.word2index:\n","                keep_input = False\n","                break\n","        # Check output sentence\n","        for word in output_sentence.split(' '):\n","            if word not in voc.word2index:\n","                keep_output = False\n","                break\n","\n","        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n","        if keep_input and keep_output:\n","            keep_pairs.append(pair)\n","\n","    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n","    return keep_pairs\n","\n","\n","# Trim voc and pairs\n","pairs_train = trimRareWords(voc, pairs_train, MIN_COUNT)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["keep_words 39230 / 105619 = 0.3714\n","Trimmed from 347643 pairs to 292057, 0.8401 of total\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AOrYQx-_1ZF1","colab_type":"code","outputId":"64f3e4db-9df1-4144-e7c4-d0f93904d833","executionInfo":{"status":"ok","timestamp":1586824174292,"user_tz":-330,"elapsed":15552,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def indexesFromSentence(voc, sentence):\n","    return [voc.word2index[word] if word in voc.word2index.keys() else RARE_WORD for word in sentence.split(' ')] + [EOS_token]\n","\n","def max_tar_len(indexes_batch):\n","  max_val = 0\n","  # print(\"indexes_batch\",indexes_batch)\n","  for i in indexes_batch:\n","    if max_val < len(i):\n","      max_val = len(i)\n","  return max_val\n","\n","def zeroPadding(l, fillvalue=PAD_token):\n","    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n","\n","def binaryMatrix(l, value=PAD_token):\n","    m = []\n","    for i, seq in enumerate(l):\n","        m.append([])\n","        for token in seq:\n","            if token == PAD_token:\n","                m[i].append(0)\n","            else:\n","                m[i].append(1)\n","    return m\n","\n","# Returns padded input sequence tensor and lengths\n","def inputVar(l, voc):\n","    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, lengths\n","\n","# Returns padded target sequence tensor, padding mask, and max target length\n","def outputVar(l, voc):\n","    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n","    #print(max(len(indexes_batch[0]),len(indexes_batch[1]),len(indexes_batch[3]),len(indexes_batch[2]),len(indexes_batch[4])))\n","    #max_target_len = max([max_tar_len(indexes,indexes_batch) for indexes in indexes_batch])\n","    max_target_len = max_tar_len(indexes_batch)\n","    padList = zeroPadding(indexes_batch)\n","    mask = binaryMatrix(padList)\n","    mask = torch.ByteTensor(mask)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, mask, max_target_len\n","\n","# Returns all items for a given batch of pairs\n","def batch2TrainData(voc, pair_batch):\n","    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n","    input_batch, output_batch = [], []\n","    for pair in pair_batch:\n","        input_batch.append(pair[0])\n","        output_batch.append(pair[1])\n","    inp, lengths = inputVar(input_batch, voc)\n","    output, mask, max_target_len = outputVar(output_batch, voc)\n","    return inp, lengths, output, mask, max_target_len\n","\n","\n","# Example for validation\n","small_batch_size = 5\n","batches = batch2TrainData(voc, [random.choice(pairs_train) for _ in range(small_batch_size)])\n","input_variable, lengths, target_variable, mask, max_target_len = batches\n","\n","print(\"input_variable:\", input_variable)\n","print(\"lengths:\", lengths)\n","print(\"target_variable:\", target_variable)\n","print(\"mask:\", mask)\n","print(\"max_target_len:\", max_target_len)\n","\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["input_variable: tensor([[ 2495,   337,   250,  4984,     5],\n","        [   18,   120,    26,    63,   848],\n","        [ 6677,  1057,  8255,   579,  2623],\n","        [   99,  4087,  3057,   458,  3002],\n","        [ 1301,   229,  1165, 11211,  2623],\n","        [  487,    99,   464,    53,   366],\n","        [ 2534, 12787,   551,   297,  2623],\n","        [ 1248,  1057,   551,    72,  1415],\n","        [ 6099, 12788,  1126,    72,    57],\n","        [ 2386,   488,  4820,    81,   954],\n","        [  287,    39, 11196,   501,   796],\n","        [ 8101,  6652,   143,  1797,   708],\n","        [ 1221,   163,   733,  1026,  3500],\n","        [ 1633,  1057,   250,    23,  1237],\n","        [  290,   754,  3551,   278,   535],\n","        [ 4252,   365,  5673,   942,   366],\n","        [ 1008,  2387,   213,  1371,  1104],\n","        [   72,  7973,  1388,  8382,  2623],\n","        [  323,  3006,   551,   344,    84],\n","        [ 2921,   226,    40,   297,    80],\n","        [ 7085,    87,    72,   310,   504],\n","        [ 4252, 12177,  1514,    18,     2],\n","        [ 1301, 12788,   467,     2,     0],\n","        [  650,    51,  7364,     0,     0],\n","        [   11,   520,   264,     0,     0],\n","        [ 3298,  8105,    53,     0,     0],\n","        [ 4252,  3006,   330,     0,     0],\n","        [24909,   185,  3160,     0,     0],\n","        [ 1345,   150,    91,     0,     0],\n","        [ 6677, 17856,    57,     0,     0],\n","        [  525,    10,   949,     0,     0],\n","        [  105,  1076,   414,     0,     0],\n","        [ 1717,  1134,     2,     0,     0],\n","        [   51,  3300,     0,     0,     0],\n","        [  548,   108,     0,     0,     0],\n","        [  344,  3937,     0,     0,     0],\n","        [ 1113,  2454,     0,     0,     0],\n","        [ 8538,  1057,     0,     0,     0],\n","        [25197, 12787,     0,     0,     0],\n","        [24909,  1057,     0,     0,     0],\n","        [ 1345, 12788,     0,     0,     0],\n","        [ 6677,    97,     0,     0,     0],\n","        [  110,   202,     0,     0,     0],\n","        [ 2534,   218,     0,     0,     0],\n","        [   76,    53,     0,     0,     0],\n","        [ 3638,   105,     0,     0,     0],\n","        [ 1085,   720,     0,     0,     0],\n","        [   53,   449,     0,     0,     0],\n","        [  105,   872,     0,     0,     0],\n","        [ 2555,     2,     0,     0,     0],\n","        [  440,     0,     0,     0,     0],\n","        [ 1085,     0,     0,     0,     0],\n","        [   81,     0,     0,     0,     0],\n","        [   80,     0,     0,     0,     0],\n","        [    2,     0,     0,     0,     0]])\n","lengths: tensor([55, 50, 33, 23, 22])\n","target_variable: tensor([[1079,  117,   39,  508, 3500],\n","        [6677,  488,  410,  508, 1237],\n","        [   2,    2,   96,  508,    2],\n","        [   0,    0,  805,  124,    0],\n","        [   0,    0,    2,    2,    0]])\n","mask: tensor([[1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [0, 0, 1, 1, 0],\n","        [0, 0, 1, 1, 0]], dtype=torch.uint8)\n","max_target_len: 5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bmBLbCkX1Y6q","colab_type":"code","colab":{}},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n","        super(EncoderRNN, self).__init__()\n","        self.n_layers = n_layers\n","        self.hidden_size = hidden_size\n","        self.embedding = embedding\n","\n","        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n","        #   because our input size is a word embedding with number of features == hidden_size\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n","                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n","\n","    def forward(self, input_seq, input_lengths, hidden=None):\n","        # Convert word indexes to embeddings\n","        embedded = self.embedding(input_seq)\n","        # Pack padded batch of sequences for RNN module\n","        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n","        # Forward pass through GRU\n","        outputs, hidden = self.gru(packed, hidden)\n","        # Unpack padding\n","        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n","        # Sum bidirectional GRU outputs\n","        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n","        # Return output and final hidden state\n","        return outputs, hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHbAsVtg1Y44","colab_type":"code","colab":{}},"source":["# Attention layer\n","class Attn(torch.nn.Module):\n","    def __init__(self, method, hidden_size):\n","        super(Attn, self).__init__()\n","        self.method = method\n","        if self.method not in ['dot', 'general', 'concat']:\n","            raise ValueError(self.method, \"is not an appropriate attention method.\")\n","        self.hidden_size = hidden_size\n","        if self.method == 'general':\n","            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n","        elif self.method == 'concat':\n","            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n","            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n","\n","    def dot_score(self, hidden, encoder_output):\n","        return torch.sum(hidden * encoder_output, dim=2)\n","\n","    def general_score(self, hidden, encoder_output):\n","        energy = self.attn(encoder_output)\n","        return torch.sum(hidden * energy, dim=2)\n","\n","    def concat_score(self, hidden, encoder_output):\n","        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n","        return torch.sum(self.v * energy, dim=2)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        # Calculate the attention weights (energies) based on the given method\n","        if self.method == 'general':\n","            attn_energies = self.general_score(hidden, encoder_outputs)\n","        elif self.method == 'concat':\n","            attn_energies = self.concat_score(hidden, encoder_outputs)\n","        elif self.method == 'dot':\n","            attn_energies = self.dot_score(hidden, encoder_outputs)\n","\n","        # Transpose max_length and batch_size dimensions\n","        attn_energies = attn_energies.t()\n","\n","        # Return the softmax normalized probability scores (with added dimension)\n","        return F.softmax(attn_energies, dim=1).unsqueeze(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"muLRe-mK1Y3h","colab_type":"code","colab":{}},"source":["class LuongAttnDecoderRNN(nn.Module):\n","    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n","        super(LuongAttnDecoderRNN, self).__init__()\n","\n","        # Keep for reference\n","        self.attn_model = attn_model\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        # Define layers\n","        self.embedding = embedding\n","        self.embedding_dropout = nn.Dropout(dropout)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n","        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","        self.attn = Attn(attn_model, hidden_size)\n","\n","    def forward(self, input_step, last_hidden, encoder_outputs):\n","        # Note: we run this one step (word) at a time\n","        # Get embedding of current input word\n","        embedded = self.embedding(input_step)\n","        embedded = self.embedding_dropout(embedded)\n","        # Forward through unidirectional GRU\n","        rnn_output, hidden = self.gru(embedded, last_hidden)\n","        # Calculate attention weights from the current GRU output\n","        attn_weights = self.attn(rnn_output, encoder_outputs)\n","        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n","        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n","        # Concatenate weighted context vector and GRU output using Luong eq. 5\n","        rnn_output = rnn_output.squeeze(0)\n","        context = context.squeeze(1)\n","        concat_input = torch.cat((rnn_output, context), 1)\n","        concat_output = torch.tanh(self.concat(concat_input))\n","        # Predict next word using Luong eq. 6\n","        output = self.out(concat_output)\n","        output = F.softmax(output, dim=1)\n","        # Return output and final hidden state\n","        return output, hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kJulzc4Z1Yyy","colab_type":"code","colab":{}},"source":["def maskNLLLoss(inp, target, mask):\n","    nTotal = mask.sum()\n","    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)))\n","    loss = crossEntropy.masked_select(mask).mean()\n","    loss = loss.to(device)\n","    return loss, nTotal.item()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zOsccvPS1YrP","colab_type":"code","colab":{}},"source":["def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n","          encoder_optimizer, decoder_optimizer, batch_size, clip):\n","\n","    # Zero gradients\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    # Set device options\n","    input_variable = input_variable.to(device)\n","    lengths = lengths.to(device)\n","    target_variable = target_variable.to(device)\n","    mask = mask.to(device)\n","\n","    # Initialize variables\n","    loss = 0\n","    print_losses = []\n","    n_totals = 0\n","\n","    # Forward pass through encoder\n","    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n","\n","    # Create initial decoder input (start with SOS tokens for each sentence)\n","    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n","    decoder_input = decoder_input.to(device)\n","\n","    # Set initial decoder hidden state to the encoder's final hidden state\n","    decoder_hidden = encoder_hidden[:decoder.n_layers]\n","\n","    # Determine if we are using teacher forcing this iteration\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    # Forward batch of sequences through decoder one time step at a time\n","    if use_teacher_forcing:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # Teacher forcing: next input is current target\n","            decoder_input = target_variable[t].view(1, -1)\n","            # Calculate and accumulate loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","    else:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # No teacher forcing: next input is decoder's own current output\n","            _, topi = decoder_output.topk(1)\n","            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n","            decoder_input = decoder_input.to(device)\n","            # Calculate and accumulate loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","\n","    # Perform backpropatation\n","    loss.backward()\n","\n","    # Clip gradients: gradients are modified in place\n","    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n","    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n","\n","    # Adjust model weights\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return sum(print_losses) / n_totals"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vEWcrxn11YmS","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","\n","'''def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)'''\n","\n","\n","def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, loadFilename,plot_every):\n","\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","    # Load batches for each iteration\n","    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n","                      for _ in range(n_iteration)]\n","\n","    # Initializations\n","    print('Initializing ...')\n","    start_iteration = 1\n","    print_loss = 0\n","    if loadFilename:\n","        start_iteration = checkpoint['iteration'] + 1\n","\n","    # Training loop\n","    print(\"Training...\")\n","    for iteration in range(start_iteration, n_iteration + 1):\n","        training_batch = training_batches[iteration - 1]\n","        # Extract fields from batch\n","        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n","\n","        # Run a training iteration with batch\n","        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n","                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n","        print_loss += loss\n","\n","        # Print progress\n","        if iteration % print_every == 0:\n","            print_loss_avg = print_loss / print_every\n","            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n","            print_loss = 0\n","\n","        if iteration % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","        # Save checkpoint\n","        if (iteration % save_every == 0):\n","            directory = os.path.join(save_dir, model_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n","            if not os.path.exists(directory):\n","                os.makedirs(directory)\n","            torch.save({\n","                #'iteration': iteration,\n","                'en': encoder.state_dict(),\n","                'de': decoder.state_dict(),\n","                #'en_opt': encoder_optimizer.state_dict(),\n","                #'de_opt': decoder_optimizer.state_dict(),\n","                #'loss': loss,\n","                'voc_dict': voc.__dict__,\n","                'embedding': embedding.state_dict()\n","            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))\n","\n","    #showPlot(plot_losses)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m-TWbetU1YhF","colab_type":"code","outputId":"2c607306-8155-4c8e-d73b-fe0fece98f5a","executionInfo":{"status":"ok","timestamp":1586824183700,"user_tz":-330,"elapsed":24808,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# Configure models\n","model_name = 'cb_model'\n","#attn_model = 'dot'\n","attn_model = 'general'\n","#attn_model = 'concat'\n","hidden_size = 500\n","encoder_n_layers = 2\n","decoder_n_layers = 2\n","dropout = 0.2\n","batch_size = 128\n","save_dir = os.path.join(\"/content/drive/My Drive/Colab Notebooks/Text_Summerization/\", \"save\")\n","\n","# Set checkpoint to load from; set to None if starting from scratch\n","loadFilename = None\n","checkpoint_iter = 20000\n","#loadFilename = os.path.join(save_dir, model_name,\n","#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n","#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n","\n","\n","# Load model if a loadFilename is provided\n","if loadFilename:\n","    # If loading on same machine the model was trained on\n","    checkpoint = torch.load(loadFilename)\n","    # If loading a model trained on GPU to CPU\n","    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n","    encoder_sd = checkpoint['en']\n","    decoder_sd = checkpoint['de']\n","    encoder_optimizer_sd = checkpoint['en_opt']\n","    decoder_optimizer_sd = checkpoint['de_opt']\n","    embedding_sd = checkpoint['embedding']\n","    voc.__dict__ = checkpoint['voc_dict']\n","\n","\n","print('Building encoder and decoder ...')\n","# Initialize word embeddings\n","embedding = nn.Embedding(voc.num_words, hidden_size)\n","if loadFilename:\n","    embedding.load_state_dict(embedding_sd)\n","# Initialize encoder & decoder models\n","encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n","decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n","if loadFilename:\n","    encoder.load_state_dict(encoder_sd)\n","    decoder.load_state_dict(decoder_sd)\n","# Use appropriate device\n","encoder = encoder.to(device)\n","decoder = decoder.to(device)\n","print('Models built and ready to go!')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Building encoder and decoder ...\n","Models built and ready to go!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AdpkTo9W1Yd0","colab_type":"code","outputId":"ec7ec015-2852-45b9-d66b-5ae076ba8370","executionInfo":{"status":"ok","timestamp":1586833704716,"user_tz":-330,"elapsed":486,"user":{"displayName":"Pavan Kumar Gurram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbfdBclEHhtxjEsVWanN7r2YpwaPLTVRyj4Vs8Cz4=s64","userId":"13992145837893218268"}},"colab":{"base_uri":"https://localhost:8080/","height":443}},"source":["# Configure training/optimization\n","clip = 50.0\n","teacher_forcing_ratio = 1.0\n","learning_rate = 0.0001\n","decoder_learning_ratio = 5.0\n","n_iteration = 20000\n","print_every = 1000\n","save_every = 10000\n","plot_every = 100\n","\n","# Ensure dropout layers are in train mode\n","encoder.train()\n","decoder.train()\n","\n","# Initialize optimizers\n","print('Building optimizers ...')\n","encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n","if loadFilename:\n","    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n","    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n","\n","# Run training iterations\n","print(\"Starting Training!\")\n","trainIters(model_name, voc, pairs_train, encoder, decoder, encoder_optimizer, decoder_optimizer,\n","           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n","           print_every, save_every, clip, loadFilename,plot_every)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Building optimizers ...\n","Starting Training!\n","Initializing ...\n","Training...\n","Iteration: 1000; Percent complete: 5.0%; Average loss: 4.0339\n","Iteration: 2000; Percent complete: 10.0%; Average loss: 3.3546\n","Iteration: 3000; Percent complete: 15.0%; Average loss: 3.1093\n","Iteration: 4000; Percent complete: 20.0%; Average loss: 2.9494\n","Iteration: 5000; Percent complete: 25.0%; Average loss: 2.8231\n","Iteration: 6000; Percent complete: 30.0%; Average loss: 2.7200\n","Iteration: 7000; Percent complete: 35.0%; Average loss: 2.6368\n","Iteration: 8000; Percent complete: 40.0%; Average loss: 2.5495\n","Iteration: 9000; Percent complete: 45.0%; Average loss: 2.4823\n","Iteration: 10000; Percent complete: 50.0%; Average loss: 2.4042\n","Iteration: 11000; Percent complete: 55.0%; Average loss: 2.3478\n","Iteration: 12000; Percent complete: 60.0%; Average loss: 2.2902\n","Iteration: 13000; Percent complete: 65.0%; Average loss: 2.2307\n","Iteration: 14000; Percent complete: 70.0%; Average loss: 2.1690\n","Iteration: 15000; Percent complete: 75.0%; Average loss: 2.1180\n","Iteration: 16000; Percent complete: 80.0%; Average loss: 2.0669\n","Iteration: 17000; Percent complete: 85.0%; Average loss: 2.0175\n","Iteration: 18000; Percent complete: 90.0%; Average loss: 1.9720\n","Iteration: 19000; Percent complete: 95.0%; Average loss: 1.9312\n","Iteration: 20000; Percent complete: 100.0%; Average loss: 1.8810\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8aJDJPmr1Yi8","colab_type":"code","colab":{}},"source":["class GreedySearchDecoder(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(GreedySearchDecoder, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, input_seq, input_length, max_length=10):\n","        # Forward input through encoder model\n","        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n","        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n","        decoder_hidden = encoder_hidden[:decoder.n_layers]\n","        # Initialize decoder input with SOS_token\n","        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n","        # Initialize tensors to append decoded words to\n","        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n","        all_scores = torch.zeros([0], device=device)\n","        # Iteratively decode one word token at a time\n","        for _ in range(max_length):\n","            # Forward pass through decoder\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n","            # Obtain most likely word token and its softmax score\n","            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n","            # Record token and score\n","            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n","            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n","            # Prepare current token to be next decoder input (add a dimension)\n","            decoder_input = torch.unsqueeze(decoder_input, 0)\n","        # Return collections of word tokens and scores\n","        return all_tokens, all_scores"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z3gCDswTTz_K","colab_type":"code","colab":{}},"source":["MAX_LENGTH=100\n","def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n","    ### Format input sentence as a batch\n","    # words -> indexes\n","    indexes_batch = [indexesFromSentence(voc, sentence)]\n","    # Create lengths tensor\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    # Transpose dimensions of batch to match models' expectations\n","    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n","    # Use appropriate device\n","    input_batch = input_batch.to(device)\n","    lengths = lengths.to(device)\n","    # Decode sentence with searcher\n","    tokens, scores = searcher(input_batch, lengths, max_length)\n","    # indexes -> words\n","    decoded_words = [voc.index2word[token.item()] for token in tokens]\n","    return decoded_words\n","\n","\n","def evaluateInput(encoder, decoder, searcher, voc):\n","    input_sentence = ''\n","    while(1):\n","        try:\n","            # Get input sentence\n","            input_sentence = input('> ')\n","            # Check if it is quit case\n","            if input_sentence == 'q' or input_sentence == 'quit': break\n","            # Normalize sentence\n","            input_sentence = clean(input_sentence)\n","            # Evaluate sentence\n","            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n","            # Format and print response sentence\n","            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n","            print('Summary:', ' '.join(output_words))\n","\n","        except KeyError:\n","            print(\"Error: Encountered unknown word.\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycfGGcHc1YSR","colab_type":"code","colab":{}},"source":["# Set dropout layers to eval mode\n","encoder.eval()\n","decoder.eval()\n","\n","# Initialize search module\n","searcher = GreedySearchDecoder(encoder, decoder)\n","\n","# Begin chatting (uncomment and run the following line to begin)\n","evaluateInput(encoder, decoder, searcher, voc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OZno6RQQ1YP4","colab_type":"code","colab":{}},"source":["pairs_val[10:50]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qE0AHVCs1YNB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6qlQ3VV_1YL2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fSZeiBjB1YKk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ogqBktT71YGG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e_xz9RNp1YDc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSZ-423E1YB1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jpq_bIU1X-i","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3x-kD9y1X8F","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}